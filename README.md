# AI-Driven-Automated-Weed-Detection-Removal-System-using-CNN-
This project presents an AI-powered embedded robotic system that automatically detects and removes weeds from agricultural fields using Convolutional Neural Networks (CNN), sensor fusion, and precision actuation. The system is designed to eliminate herbicide usage, protect crops, and automate weed management with high accuracy in real time.
The system integrates computer vision, LiDAR-based depth mapping, and a 2D linear actuator to physically remove weeds.
All processing happens on the edge, enabling real-time performance in outdoor farming conditions.

ğŸ” Key Features

Real-time weed vs crop classification using YOLOv11/YOLOv12 (CNN-based)

Camera + LiDAR fusion for accurate 3D localization

Precision mechanical weed removal using ESP32-controlled linear actuator

Fully embedded edge AI pipeline using NVIDIA Jetson Xavier NX

Herbicide-free automated weed management

Robust outdoor-ready electronics with custom power boards

ğŸ§  System Workflow

1ï¸âƒ£ Image Acquisition

A high-resolution camera captures live images of plants as the robot moves through crop rows.

2ï¸âƒ£ Weed Detection using CNN (YOLOv11/YOLOv12)

Processed on NVIDIA Jetson Xavier NX

Custom-trained CNN model detects weed vs crop

Bounding box + pixel coordinates extracted in real time

3ï¸âƒ£ Weed Localization (Camera + LiDAR Fusion)

RPLiDAR A2M12 collects distance data

Pixel coordinates + depth values are fused

Calculates real-world weed position (X, Y) relative to robot

4ï¸âƒ£ Weed Removal Mechanism

Coordinates are sent to ESP32

A 2D linear actuator stage moves accurately to the weed position

A mechanical tool removes the weed without damaging nearby crops

5ï¸âƒ£ Embedded Control System

Custom DC-DC converters & power management

Closed-loop alignment to maintain robot path

Reliable operation in harsh outdoor environments

ğŸ§© High-Level System Architecture

Camera â”€â”€â–º Jetson NX â”€â”€â–º CNN (YOLOv11/12)
                     â””â”€â–º Pixel Coordinates
LiDAR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Distance Data
                     â–¼
              Sensor Fusion
                     â–¼
             Real-world Weed Location
                     â–¼
                   ESP32
                     â–¼
        2D Linear Actuator + End Effector
                     â–¼
            Mechanical Weed Removal

ğŸ”§ Hardware Used

NVIDIA Jetson Xavier NX â€“ AI inference

High-resolution camera â€“ plant imaging

RPLiDAR A2M12 â€“ distance mapping

ESP32 â€“ actuator + low-level control

2D linear actuator system â€“ physical weed removal

Custom power & DC-DC converter board

Outdoor-rated mechanical assembly

ğŸ§‘â€ğŸ’» Software Stack
Component	Technology
CNN Model	YOLOv11 / YOLOv12
Jetson Code	Python, OpenCV, NumPy
Embedded Firmware	ESP32 (Arduino/FreeRTOS)
Fusion Algorithm	Cameraâ€“LiDAR calibration & mapping
Communication	UART / Serial
Visualization	Optional RViz / matplotlib
ğŸ“Š Model Training (Short Summary)

Dataset collected from real crop fields

Annotated for crop and weed classes

Trained YOLOv11/YOLOv12 for fast CNN inference

Optimized using TensorRT for Jetson NX

Achieved strong outdoor detection accuracy


ğŸ“Œ Future Enhancements

Multi-row autonomous robot

Solar-powered version

Implement semantic segmentation (Mask-based weed removal)

IMU + RTK GPSâ€“based navigation

Multi-tool end-effector for different weed types
